% SOW must be emailed to the course instructor at akhamis@pami.uwaterloo.ca
% with subject SOW-[Your Project number] no later than June 9, 2014.

% (We are team #27)

\documentclass[a4paper]{article}

\usepackage[style=ieee,sorting=none,dateabbrev=false,backend=biber]{biblatex}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{parskip}
\usepackage{amssymb}
\usepackage{upgreek}
\usepackage{todonotes}
\usepackage{csquotes}

\addbibresource{report.bib}

% Allow for sub^3sections and sub^4sections
% http://pleasemakeanote.blogspot.com/2010/06/how-to-activate-subsubsubsection-in.html
\setcounter{secnumdepth}{5}
\newcommand{\subsubsubsection}[1]{\paragraph{#1} \mbox{}}
\newcommand{\subsubsubsubsection}[1]{\subparagraph{#1} \mbox{}}

\newcommand\Forall{\mathop{\mbox{\Large $\mathsurround0pt\forall$}}}


\title{Complex Task Allocation: A Comparison of Metaheuristics}
\author{
	Group 27 \\
	\\
	Lucas Wojciechowksi, Ariel Weingarten, Alexander Maguire, \\
	Austin Dobrik, Dane Carr}
\date{\today}

\begin{document}

\maketitle

% TODO Write out all irrational numbers to 4 decimal points
% TODO Represent solutions as S_0^3
% TODO All tasks must be 1-indexed
% TODO All robots must be 1-indexed
% TODO We must use a consistent naming convention for robots/sensors, homes/homes, tasks
% TODO We must use a consistent formatting in representing solutions, esp sentinal values
% TODO Do number equations and reference them by their number

\section*{Summary}
% The summary should be a brief version of the full report It should give the
% reader an accurate overview Be brief, but be specific.
This report is an analysis of the efficacy of different metaheuristic algorithms in solving a complex task allocation problem.
Complex task allocation is the assignment of complex and simple tasks to a group of robots. This report is taking an optimization-based approach to solve a multi-task robot, single-robot task, instantaneous assignment version of the multirobot task assignment problem that adopts a decompose-then allocate strategy to handle complex tasks.

Five metaheuristic algorithms were tested for this report. They are: Tabu Search, Simulated Annealing, Genetic Algorithms, Particle Swarm Optimization, and Ant Colony Optimization.

These algorithms will be run on a dataset that INSERT DESCRIPTION OF THE DATASET HERE.

The results of experimentation are as follows. The algorithm that produced the most optimal solution in ITERATIONS is ALGORITHM.
If computation time needs to be minimized, then ALGORITHM is able to produce the most optimal solution in SMALLER NUMBER of ITERATIONS.

In conclusions, this report recommends the use of ALGORITHM.

\section{Introduction}
% Why is the problem important
\subsection{Problem Context}

As the digital revolution leaves the second digital wave behind, and embraces the robotics wave\cite{Talk}, it is becoming increasingly important to prepare for the multitude of situations where robots will be available to complete various tasks.

In particular, Multirobot Systems (MRS) are becoming a high interest subject. An MRS is a group of robots that are designed with the intent of performing a collective behavior.

There are numerous advantages associated with a group of simple robots over a single multi-purpose robot. For example, it is simpler to design a robust single purpose robot than a robot with multiple abilities and configurations. Simple designs tend to be more robust and lead to more reliable robots. Another source of reliability is that a group of robots can accommodate some degree of redundancy in composition.  In addition, many complex tasks are distributed over a large area and would be slow to accomplish with a single-agent system. Examples of problems that can be solved by MRSs are search and rescue in burning building, surveillance and space construction.

% What is the problem
\subsection{Multirobot Task Allocation}

This report is specifically considering the problem of Complex Task Allocation for an MRS where the tasks are related to surveillance. The problem statement reads as follows:\mbox{}
\blockquote{In mobile surveillance systems, complex task allocation addresses how to optimally assign a set of surveillance tasks to a set of mobile sensing agents to maximize overall expected performance, taking into account the priorities of the tasks and the skill ratings of the mobile robots.}
This problem is important to solve because areas under surveillance usually possess some degree of danger. Being able to replace human sentinels with robots has the potential to save the lives of the surveyors and of nearby civilians by providing advanced warning of incoming threats. The task allocation problem within the broader scope of surveillance is important because an optimal solution represents an effective assignment of robots to tasks and improves the overall efficacy of the MRS. Colloquially speaking, this report answers the question of ``which robot should perform which task?''\cite{Badreldin}


% Enumeration of report objectives and report structure
\subsection{Report Structure and Direction}

The purpose of this report is to categorize which metaheuristic optimization techniques are effective within a given scenario. For example, which algorithms are better-suited for online analysis and which for offline analysis.

The report will continue with a review of existing literature and identifying the commonalities and differences with the solution presented in this report. Then we will present a problem formulation and model from which we will implement our algorithms. The paper then describes how the well-known Traveling Salesman Problem can be adjusted for use with Complex Task Allocation. From there, the report identifies the criteria upon which each meta heuristic technique's performance is evaluated. Then the results of running each technique are then presented against these performance criteria. From these results, conclusions are drawn and recommendations for future work are suggested.



%  [1] [Alaa Khamis, Cooperative Multirobot Systems, Plenary Talk at IAC2014]
%  [2]``Complex Task Allocation in Mobile Surveillance Systems'',
%  \cite{Badreldin} ``A comparative Study between Optimization and Market-based Approaches to Multi-robot Task Allocation''.
%  [4] A Framework For Studying Multirobot Task Allocation (mrs03.pdf)Brian P. Gerkey, Maja J. Mataric

% Summarize the importance of the problem you are trying to solve and the reason that motivated you to select this project. Explain what was the problem or challenge that you were given? state the purpose of the project and how did you solve it? Enumerate the objectives of the project and describe in brief the structure of the report.


\section{Literature Review}
% The following papers were reviewed to obtain some perspective on different approaches to complex task allocation:
% ``Complex Task Allocation in Mobile Surveillance Systems'', ``A comparative Study between Optimization and
% Market-based Approaches to Multi-robot Task Allocation''.

An examination of existing literature reveals two predominant schools of approach to solving Multi-Robot Task Allocation (MRTA). There are market-based and optimization-based approaches.
The market-based approach is inspired from the development of market economies in human societies.
Each robot is made analogous to an individual seeking profit within a market and as a result, effecting a redistribution of resources within the environment.
The optimization-based approach is rooted in mathematics rather than socio-economic observation.
The thrust is to identify an equation that captures the constraints contained in a problem and to find a solution that either maximizes the profit or minimizes the cost of a given solution.
The goal of this report is to perform a comparative study of metaheuristic techniques and so this directs the attention of this paper onto an optimization-based approach for solving MRTA. Though Khamis et al.\cite{Khamis} propose a method for using a market-based approach to generate candidate solutions that are then fed into a metaheuristic algorithm.\\

In \textit{Complex Task Allocation in Mobile Surveillance Systems}\cite{Khamis}, Khamis et al. describe a taxonomy for classifying MRTA problems examined in literature. From their taxonomy, the MRTA problem examined by this report has the following classifications:

\begin{enumerate}
\item Multi-task robots: Each robot is able to perform various tasks, and has a certain skill at each type of task.
\item Single-robot tasks: Each task can be completed by a single robot.
\item Instantaneous Assignment: The assignment of tasks to robots will be calculated once and will not be updated dynamically as the robots execute their given task list.
\end{enumerate}

The scope of this report will focus on a decompose-then-allocate approach towards complex tasks. That is, all complex tasks will be broken up into subtasks that will then be assigned out to particular robots. This makes a strong assumption about the independence of the subtasks, but is not without precedence in the literature.\cite{Khamis}\\

In Gerkey's \textit{A Framework for Studying Multirobot Task Allocation}\cite{Gerkey}, he identifies MRTA as an instance of the Optimal Assignment Problem (OAP). The OAP considers $n$ workers who have various skill levels at $m$ jobs that must be completed, and seeks a mapping of workers to jobs that optimizes overall performance. At first this seems like an ideal problem to map MRTA onto, but there are a few shortcomings for the particular instance of MRTA being studied in this report. Robots are not being assigned to a single task, but rather are given a tour of several tasks through a given area of interest. The importance of considering distance traveled, in addition to the cost associated in a task-robot mapping, make the Traveling Salesman Problem (TSP) a more natural problem to map this instance of MRTA onto.\\

% Contrast our approach to mTSP to \cite{Badreldin}'s approach to mTSP
% we make task completion time a per-robot value rather than a per-task value
This report makes use of the multiple Travelling Salesman Problem (mTSP) formulation as described by Badreldin, Hussein, and Khamis with some important differences.\cite{Badreldin} Instead of including a robot aging factor, an energy capacity feature has been identified to put a harder constraint on robot tour lengths. In addition, instead of considering a minimum task completion time that holds for all robots, each type of robot has its own task completion time. This explicitly decouples a robot's skill at a task from the time it takes to complete the task. It also more accurately represents that different types of robots can have radically different methods for accomplishing the same task. To reconcile this change with the idea that tasks have certain requirements, a time of infinity is assigned to robots who lack any skill at a particular task.

% Conduct a critical survey on different/similar solutions and explain how your
% solution extends or differs from these solutions.

% This project should start by studying comprehensively the problem in order
% to characterize its complexity and its main challenges. Collect related
% resources and conduct a critical survey on similar solutions reported in the
% literature.

% Collect resources and think about how to explain any of the topics below
%  - Motivation
%  - Definition
%  - [*] Categorization
%  - Challenges
%  - Applications

% Suggested reference papers:
%
%  - Alaa Khamis, Ahmed Elmogy and Fakhreddine Karray, "Complex Task Allocation
%    in Mobile Surveillance Systems," Journal of Intelligent and Robotic Systems,
%    Springer
%  - Mohamed Badreldin, Ahmed Hussein and Alaa Khamis, "A Comparative Study
%    between Optimization and Market-based Approaches to Multi-robot Task
%    Allocation," Advances in Artificial Intelligence Journal, 2013.
%  - Alaa Khamis, Cooperative Multirobot Systems, Plenary Talk at IAC2014].

\section{Problem Formulation and Modeling}

% Include the problem statement and describe its model.

% In this step, an initial statement of the problem should be made. The
% internal and external factors and the objective(s) of the problem must be
% outlined. Describe the problem as standard optimization problem as
% following:
%
% Find
% $$X = {x_1, x_2, ..., x_n}^T$$
% which minimizes/maximizes $f(X)$ subject to equality constraints
% $$\forall j \in [1, m], l_j(X) = 0$$
% and inequality constraints
% $$\forall j \in [1, p], g_j(X) \leq 0$$
% (see "specification for statement of work.pdf" for a visual representation)
%
% Define the decision variable or design vector, objective function/s and the
% problem constraints.

% Include the problem statement and describe its modeling If you think there is
% a need to explain background information regarding some supplementary methods
% used in your formulation, do that here

\subsection{Problem Formulation}

% TODO explicitly indicate that everything is 1 indexed

Suppose we have a set of ``tasks", $\{1, 2, ..., n_\mathit{tasks}\}$, which need to be completed by a set of ``robots", $\{1, 2, ..., n_\mathit{robots}\}$.

We seek a ``solution", $S$, that consists of an assignment of each robot an ordered set of tasks for it to complete, a ``tour", such that each task is performed exactly once and our overall cost is minimized. Each tour begins and ends at the robot's ``home".
$$
\Forall_{r=0}^{n_\mathit{robots}}
S(r) = \{ \mathit{home}(r), t_1, t_2, ..., t_n, \mathit{home}(r) \}
$$

\subsubsection{Canonical Solution Representations}
The overall solution $S$ has a canonical vector representation as an n-tuple, consisting of a permutation of the set:
$$
\{1, 2, \dots n_{tasks}\} \cup \{0\}^{n_{robots}-1}
$$

This tuple is read from left to right, and describes the concatenation of each $robot_i$'s path, using 0 to mark the end of a path. This 0 is henceforth known as a sentinel value. This representation \textbf{does not} include $robot_i$ starting at or returning to $\mathit{home}(i)$, since this information is redundant by the problem definition.

To help cement this important representation in the reader's mind, consider the following canonical solution vector:
$$
\{3,4,2,0,0,1,5\}
$$ 
which should be interpreted as
\begin{itemize}
\item $S(1) = \{ home_1, 3, 4, 2, home_1 \}$
\item $S(2) = \{ home_2, home_2 \}$
\item $S(3) = \{ home_3, 1, 5, home_3 \}$
\end{itemize}

\subsubsection{Data Homogeneity}

For simplicity and homogeneity of internal data models, we represent homes as tasks:
$$\mathit{home}(r) = n_\mathit{tasks} + r$$

Subject to the following constraints:
$$
\mathit{task\,time}(\mathit{home}(i)) = 0 \qquad \forall i \in \mathit{robots}
$$
$$
\mathit{priority}(\mathit{home}(i)) = 0 \qquad \forall i \in \mathit{robots}
$$
$$
\mathit{distance}(\mathit{home}(i), \mathit{home}(j)) = 0 \qquad \forall i, j \in \mathit{robots}
$$


\subsubsection{Overall Cost}

We will consider a multi-objective cost function, $\mathit{cost}$, that accounts for
\begin{enumerate}
\item $\mathit{cost}_\mathit{time}$, how long it takes to complete all tasks, assuming the robots work in parallel
\item $\mathit{cost}_\mathit{energy}$, whether or not each robot is able to complete its tour before running out of ``energy"
\item $\mathit{cost}_\mathit{quality}$, how well the tasks are completed relative to their priorities
\end{enumerate}

We define overall $\mathit{cost}$ as a linear combination of these cost functions, introducing two constants, $\alpha$ and $\beta$.
$$
\mathit{cost}(S) =
  \alpha \beta \, \mathit{cost}_\mathit{time}(S) +
  (1-\alpha) \mathit{cost}_\mathit{quality}(S) +
  \mathit{cost}_\mathit{energy}(S)
$$

$\alpha$ is a tuning parameter allowing for the relative importance of quality vs time to be adjusted. $\alpha = 1$ places all emphasis on time; $\alpha = 0$ places all emphasis on quality.

$\beta$ is a normalization parameter that makes $\mathit{cost}_\mathit{time}$ directly comparable to $\mathit{cost}_\mathit{quality}$. It is discussed in further the next section.

\subsubsection{Time Cost}

The time it takes to travel between tasks is a function of ``distance" and ``velocity." Each robot, $r$, may travel at a different velocity, measured in units distance per units time.
$$\mathit{velocity}(r) > 0, \in \mathbb{R}$$
Each task, $t$, may be a different distance from each other task, $u$. For simplicity, we represent home locations as tasks.
$$\mathit{distance}(t, u) > 0, \in \mathbb{R}$$

Additionally, each robot, $r$ may complete each task, $t$, in a different amount of time.
$$\mathit{task \, time}(r, t) > 0, \in \mathbb{R}$$

The total amount of time it takes for a robot, $r$, to complete a tour, $o$, is given by
$$
\mathit{tour \, time}(r, o) =
  \left(
    \sum^{|o|}_{t=2} \mathit{distance}(t - 1, t) \cdot \mathit{velocity}(r)
  \right) +
  \left(
    \sum^{|o|}_{t=1} \mathit{task \, time}(r, t)
  \right)
$$

We define $\mathit{cost}_\mathit{time}$ as the amount of time it takes to complete all tasks, assuming the robots work in parallel; effectively the max tour time across all robots.
$$
\mathit{cost}_\mathit{time}(S) =
  \max_{r=1}^{n_\mathit{robots}}
  \mathit{tour \, time}(r, S(r))
$$

In the overall cost function, $\beta$ is a normalization parameter that makes $\mathit{cost}_\mathit{time}$ directly comparable to $\mathit{cost}_\mathit{quality}$. Because skills and priorities are bounded $\in [0, 1]$, we are guaranteed that, for some tour $o$ and some robot $r$, $\mathit{cost}_\mathit{quality}(r, o) \in [0, |o|]$. To make $\mathit{cost}_\mathit{time}$ directly comparable to $\mathit{cost}_\mathit{quality}$, we must scale $\mathit{cost}_\mathit{time}$ using $\beta$ such that it has the same bounds, $\in [0, |o|]$. Such a $\beta$ may be calculated as
$$
\beta =
    \frac
      {n_\textit{robots}}
      {
        2 \cdot
        \max \left(
          \frac
            { \max\limits_{r=1}^{n_\mathit{robots}} \max\limits_{t=1}^{n_\mathit{tasks}} \mathit{distance}(r, t) }
            { \min\limits_{r=1}^{n_\mathit{robots}} \mathit{velocity}(r) },
          \max\limits_{r=1}^{n_\mathit{robots}} \max\limits_{t=1}^{n_\mathit{tasks}} \mathit{task \, time}(r, t)
        \right)
      }
$$

\subsubsection{Energy Cost}

Each robot, $r$, may be capable of a spending different amount of time on tour. One unit energy equates to the ability to spend one additional unit time on tour.
$$\mathit{energy}(r) > 0, \in \mathbb{R}$$

We define $\mathit{cost}_\mathit{energy}$ to evaluate to 0 if this hard constraint is met for all robots, and $\infty$ otherwise
$$
\mathit{cost}_\mathit{energy}(S) = \begin{cases}
0 & \text{if } \mathop{\forall}\limits_{r=0}^{n_\mathit{robots}} \mathit{energy}(r) \geq \mathit{tour \, time}(r, S(r)) \\
\infty & \text{otherwise}
\end{cases}
$$

\subsubsection{Quality Cost}

We define $\mathit{cost}_\mathit{quality}$ to represent the skill with which each task was done relative to that task's priority. This is quantified as the sum of all the products of the skill with which a task was done by the priority that task had.
$$
\mathit{cost}_\mathit{quality}(S) =
  \sum^{n_\mathit{robots}}_{r=1}
  \sum^{|S(r)|}_{t=1}
  1 - \mathit{priority}(r, t) \cdot \mathit{skill}(r, t)
$$
Since a performing a high priority task with a highly skilled robot is desirable and we want to treat minimize cost, we subtract the maximum possible value, 1, from the product of the priority and skill (recall that $\mathit{skill}(r) \in [0, 1]$ and $\mathit{priority}(r, t) \in [0, 1]$).

% \subsection{Normalization}

% Note that many of the above quantities ($\mathit{priority}$, $\mathit{skill}$, $\mathit{distance}$, $\mathit{velocity}$, and $\mathit{taskTime}$) must be $\in [0 ,1]$. Raw data must be normalized to be within this rage.

% This is trivial for $\mathit{priority}$ and $\mathit{skill}$: divide all
% priorities by the max priority. Skills may be treated likewise.

% Normalizing the $\mathit{distance}$, $\mathit{velocity}$, and
% $\mathit{taskTime}$, however, is a little more tricky.

% Suppose you have unnormalized $\mathit{distance}'$, $\mathit{velocity}'$, and
% $\mathit{taskTime}'$ Calculate $\beta$ as


% We can then obtain normalized $\mathit{distance}'$, $\mathit{velocity}'$, and
% $\mathit{task \, time}'$ as
% \begin{align*}
% \mathit{distance} & = \mathit{distance}' \cdot \frac{1}{\beta} \\
% \mathit{velocity} & = \mathit{velocity}' \cdot \frac{1}{\beta} \\
% \mathit{task \, time} & = \mathit{task \, time}' \cdot \frac{1}{\beta}
% \end{align*}

\subsection{Modeling as Traveling Salesman Problem (TSP)}

% In this important step, an abstract mathematical model is built for the
% problem. The modeler can be inspired by similar models in the literature.
% This will reduce the problem to well-studied optimization models. Usually,
% models we are solving are simplifications of the reality. They involve
% approximations and somecdot they skip processes that are complex to
% represent in a mathematical model. For example, travelling salesman problem
% (TSP) and multiple travelling salesman problem (mTSP) are commonly used as
% models for real-life problems such as school bus routing problem and complex
% task allocation problem.
\subsubsection{Adaptation}
The area of interest for the robots in the MRS can be represented as a two dimensional bounded space. Within this space, the location of tasks and robot home locations can be represented as a graph. As described in the previous section, the goal is to create an assignment of tasks to robots which minimizes the total cost of travel. This makes the MRTA problem a good fit for reduction to the mTSP problem. This report will be making use of some well-studied variations of mTSP \cite{Badreldin}.
\begin{enumerate}
\item \textbf{Salesmen starting node}: Robots are not guaranteed to start from the same node and must end their tour by returning to their starting node.
\item \textbf{Number of salesmen}: The number of robots can vary between instances of this problem, but is static for the duration of any given instance.
\item \textbf{City time frame}: Robots take a certain amount of time to complete a task and therefore spend a certain amount of time at a given node.
\item \textbf{Fair division of salesmen}: There are constraints on the maximum amount of work that a robot can perform on their tour and so the required traveling should be distributed amongst the available agents in a relatively fair manner as defined by the problem parameters.
\end{enumerate}

In an MRS, there is heterogeneity in robot composition. This requires the augmentation of the ``salesman'' idea to support some differentiating factors. This report has identified 3 main features:

\begin{enumerate}
\item \textbf{Velocity}: Each robot has a speed at which they travel between tasks.
\item \textbf{Energy}: Each robot has an energy capacity that restricts how long it can be away from its home node.
\item \textbf{Skill}: Each robot has a skill rating that represents its ability to complete a task.
\item \textbf{Task Completion Time}: Robots do not necessarily take the same amount requires a different amount of time to complete

\end{enumerate}

In this MRTA problem, there is also heterogeneity in the tasks that area assigned to visit. For this reason, the idea of ``cities'' have been augmented with the following features:

\begin{enumerate}
\item \textbf{Priority}: Some tasks are more important that others and should be considered first.
\end{enumerate}

The next section describes the graph that will be constructed for use with mTSP.

\subsubsection{The Graph}
We will model complex task allocation loosely on the traveling salesman problem.

Given a population of $\mathit{robots}$, a set of $\mathit{tasks}$, a set of $\mathit{homes}$ a priority for each task $P$, each robot's skill at performing each task $M_{skill}(r,t)$ and an ordered assignment of tasks to robots $S(r)$, for each $r \in \mathit{robots}$
we can create a directed, weighted graph as follows:

Given a random initial solution, $S_0$,

\begin{align*}
	G &= (V, E) \\
	V &= \mathit{homes} \cup \mathit{tasks} \\
	E_{i, j} &= distances(i,j) \qquad \forall i,j \in [1, nRobots+nTasks] \\
\end{align*}
%

That is, we create a graph that shows the distances between every task and the distances between every task and every home.

From here, we can run TSP on the created graph. The cost of taking each edge will be determined using $w$ which will take in the distance represented by that edge as an input. Every robot starts at their home.

\subsection{Reduced Size Problem}

% Describe a reduced version of the problem in order to be used to perform
% hand-iterations. For example, if you are studying plant layout problem
% (PLP), a reduced size problem may contain only 4 departments (facilities)
% and 4 locations.

% Describe a small scale problem of the original one Try to perform hand
% iterations to make sure modeling is done properly

In this section, we define a reduced size complex task allocation problem which
will be used to perform hand-iterations of various optimization algorithms in
the following sections.

Suppose we have two robots with the following attributes:

\begin{center}
\begin{tabular}{lll}
        & \textbf{velocity} & \textbf{energy} \\
\textbf{robot 1} & 0.9146   & 58.2024          \\
\textbf{robot 2} & 0.6509   & 45.0418
\end{tabular}
\end{center}
\vspace{1em}

These robots must complete three tasks:

\begin{center}
\begin{tabular}{llllll}
                &                   & \textbf{robot 1} & \textbf{robot 1} & \textbf{robot 2} & \textbf{robot 2} \\
                & \textbf{priority} & \textbf{skill}   & \textbf{time}    & \textbf{skill}   & \textbf{time} \\
\textbf{task 1} & 0.7761            & 0.97195          & 2.5511           & 0.33896          & 6.1632        \\
\textbf{task 2} & 0.3663            & 0.46364          & 8.8416           & 0.44659          & 3.7353        \\
\textbf{task 3} & 0.8863            & 0.83202          & 6.1189           & 0.02791          & 3.0623
\end{tabular}
\end{center}
\vspace{1em}

The distances between tasks and home locations are:

\begin{center}
\begin{tabular}{llllll}
                & \textbf{task 1} & \textbf{task 2} & \textbf{task 3} & \textbf{home 1} & \textbf{home 2} \\
\textbf{task 1} &   -             & 3.7604          & 6.2783          & 9.3271          & 1.4957 \\
\textbf{task 2} & 8.0510          &   -             & 8.4473          & 1.3190          & 4.9917 \\
\textbf{task 3} & 3.2972          & 8.5977          &   -             & 8.5270          & 0.4359 \\
\textbf{home 1} & 2.5143          & 8.4739          & 4.6241          &    -            &    -   \\
\textbf{home 2} & 1.2170          & 6.1530          & 3.9628          &    -            &    -
\end{tabular}
\end{center}

\subsection{Real Problem}

% The real size problem formulation and modeling will be used to show the
% ability of the proposed solutions implemented in handling large size
% problems.

% Gradually Increase the size of problem to study the scalability of your model
% Some models will fail in this step (any examples? Is the any way to know that
% beforehand?)

\section{Proposed Solution}

% Once the problem is formulated and modeled, the five main algorithms studied
% in this course (TA, SA, GA, PSO and ACO) must be applied to generate a “good”
% solution for the problem. The solution may be optimal or suboptimal.

% At least two hand iterations must be performed on the reduced size problem to
% show how to use the studied algorithms in solving the selected problem.

% The studied algorithms must be implemented from scratch using Matlab/Octave
% without using any toolboxes.

%  - Generate an initial solution.
%  - Suggest a cost function (objective function) suitable for this problem.
%  - Define a suitable neighborhood operator.
%  - Define a suitable solving strategy for this problem.
%  - Select your own values for the parameter and explain the basis for your
%      selection.
%  - Describe how each algorithm (TS, SA, GA, PSO and ACO) will proceed to
%       solve this problem by performing at least two hand iterations on a
%       reduced version of the problem.
%  - Implement the proposed solution using Matlab/Octave.

% Once the problem is formulated and modeled, the five main algorithms studied
% in this course (TA, SA, GA, PSO and ACO) must be applied to generate a “good”
% solution for the problem. The solution may be optimal or suboptimal.

% Apply five main optimization algorithms (TS, SA, GA, PSO, and ACO) Try to
% generate a “good” solution that may be optimal or sub-optimal

% Include at least two hand iterations on the reduced size of the problem The
% studied algorithms should be implemented from scratch in Matlab / Octave.
% Using toolboxes are NOT allowed.

In this section, we will consider five metahuristics in the context of complex task allocation:
\begin{itemize}
\item tabu search algorithm
\item simulated annealing algorithm
\item genetic algorithm
\item particle swarm optimization algorithm
\item ant colony optimization algorithm
\end{itemize}

% TODO will we also discuss perf in this section?
In the following subsections, we will, for each metaheuristic, provide a brief
high level description of the algorithm, show and explain two ``hand iterations"
on the reduced problem, and provide a Matlab implementation.

All hand iterations will use $\alpha = 0.5$, treating time and quality costs
equally, and $\beta = 0.06979$, calculated as specified in section 3.2.1. Where applicable
we will use the ``randomly" selected initial solution, $S_0 = [ 1, 2, 0, 3 ]$.

\subsection{Tabu Search Algorithm} % Lucas

\subsubsection{Description}

Tabu Search Algorithm is one of the easiest algorithms to implement because it modifies only one solution and contains only one improvement over Hill Climbing and that is the additon of a tabu list. The tabu list contains all of the recent moves taken by the algorithm which forces the algorithm to diversify if the algorithm is stuck in a local minima.

The algorithm works by maintaining a tabu list that contains all of the moves that are not allowed. After a move is taken the tenure value is put in the tabu list and then the rest of the values in the tabu list are decremented. By decrementing values in the tabu table this will make these moves available in the next step if their tabu value reaches 0. The only tuning that must be done in this algorithm is to modify the tenure value.

\subsubsection{Hand Iterations}

In these hand iterations, we will use a tabu tenure of 1 and and aspiration criteria that allows globally improving but tabu solutions to be considered.

\subsubsubsection{Iteration 1}

We begin with our randomly selected initial solution, and initial global best
$$S_\textit{best} = S_0 = [ 1, 2, 0, 3 ], \; \textit{cost}(S_\textit{best}) = 3.1617$$

Next, we find all neighboring solutions and evaluate the cost of each. No solutions are tabu yet because our tabu list is empty
\begin{center}
\begin{tabular}{lllll}
& \textbf{swap}   & \textbf{solution}    & \textbf{tabu?} & \textbf{cost}  \\
$S_{1,1}$ & $1,2$ & $[2, 1, 0, 3]$ & no & $3.8583$ \\
$S_{1,2}$ & $1,3$ & $[0, 2, 1, 3]$ & no & $\infty$ \\
$S_{1,3}$ & $1,4$ & $[3, 2, 0, 1]$ & no & $3.6619$ \\
$S_{1,4}$ & $2,3$ & $[1, 0, 2, 3]$ & no & $3.5146$ \\
$S_{1,5}$ & $2,4$ & $[1, 3, 0, 2]$ & no & $3.7910$ \\
$S_{1,6}$ & $3,4$ & $[1, 2, 3, 0]$ & no & $4.3288$ \\
\end{tabular}
\end{center}
\vspace{1.5em}

Observe that $S_{1,4}$ has the lowest cost and is not tabu. Therefore, we let
$$S_{1, \textit{best}} = S_{1,4} = [1, 0, 2, 3], \; \textit{cost}(S_{1, \textit{best}}) = 3.6619$$
However, $S_\textit{best}$ is not updated because $S_{1, \textit{best}}$'s cost is higher.

Since this solution was created by swapping elements 2 and 3 in $S_0$, we mark those in our tabu list with a tenure of 1
\begin{center}
\begin{tabular}{lllll}
\textbf{position} & 1 & 2 & 3 & 4 \\
\textbf{tenure}   & 0 & 1 & 1 & 0
\end{tabular}
\end{center}
\vspace{1.5em}

\subsubsubsection{Iteration 2}

We begin by finding all neighboring solutions of $S_{1, \text{best}} = [1, 0, 2, 3]$
\begin{center}
\begin{tabular}{lllll}
& \textbf{swap}   & \textbf{solution}    & \textbf{tabu?} & \textbf{cost}  \\
$S_{2,1}$ & $1,2$ & $[0, 1, 2, 3]$ & yes & 3.4210 \\
$S_{2,2}$ & $1,3$ & $[2, 0, 1, 3]$ & yes & 2.9759 \\
$S_{2,3}$ & $1,4$ & $[3, 0, 2, 1]$ & no  & 3.7690 \\
$S_{2,4}$ & $2,3$ & $[1, 2, 0, 3]$ & yes & 3.1617 \\
$S_{2,5}$ & $2,4$ & $[1, 3, 2, 0]$ & yes & 4.1556 \\
$S_{2,6}$ & $3,4$ & $[1, 0, 3, 2]$ & yes & 3.6494 \\
\end{tabular}
\end{center}
\vspace{1.5em}

Observe that $S_{2,2}$ has the lowest cost. Although this solution is tabu, it is has a lower cost than $S_\textit{best}$, so we allow it to become $S_{2, \textit{best}}$ and $S_\textit{best}$.

We decrement the tenure of all elements in the tabu list. Since this solution was created by swapping elements 1 and 3 in $S_{1, \textit{best}}$, we mark those in our tabu list with a tenure of 1

\begin{center}
\begin{tabular}{lllll}
\textbf{position} & 1 & 2 & 3 & 4 \\
\textbf{tenure}   & 1 & 0 & 1 & 0
\end{tabular}
\end{center}
\vspace{1.5em}

After two iterations, we have
$$S_{\text{best}} = [2, 0, 1, 3], \; \textit{cost}(S_{\text{best}}) = 2.9759$$

\subsection{Simulated Annealing Algorithm} % Dane

The simulated annealing metaheuristic is based on the physical annealing process, used to alter the properties of materials through controlled cooling.\cite{Kirkpatrick} A cost function specific to the problem is used to represent the ``energy'' of a particular solution. The minimum energy state represents the optimal solution. Controlled cooling is used to find a near-optimal solution, similar to how particles settle into a stable, low-energy configuration in physical annealing. Since there is no concept of temperature in general optimization problems, an artificial temperature value $T$ is used to represent the temperature of the system.

The algorithm begins with a random solution. At each iteration, a random solution is selected from the current solution's set of neighbours. The probability of selecting the new random solution over the old solution is $\mathit{P}(\Delta{}E) = e^{-\frac{\Delta{}E}{k_{B}T}}$, based on the Boltzmann probability factor.\cite{Kirkpatrick} The probability function ensures that any improving solution is accepted, and that there is a possiblity to accept any non-improving solution when $T>0$. When the temperature is high, there is a high probability of selecting non-improving solutions, which decreases as the temperature decreases. As the algorithm reaches the minimum temperature, it should converge to an optimal or near-optimal solution.

\subsubsection{Hand Iterations}

In these hand iterations, a geometric cooling schedule will be used with an initial temperature $T_0 = 3$ and cooling factor $\alpha_\mathit{cooling} = 0.8$
$$T_i = T_0 \cdot \left( \alpha_\mathit{cooling} \right)^{i - 1}$$

\subsubsubsection{Iteration 1}

We begin with our randomly selected initial solution
$$S_\mathit{best} = S_0 = [ 1, 2, 0, 3 ], \; \mathit{cost}(S_0) = 3.1617$$
and swap two randomly selected elements (4 and 3) to create a neighboring
solution, $S_1$
$$S_1 = [ 1, 2, 3, 0 ], \; \mathit{cost}(S_1) = 4.3288$$

To decide whether or not $S_1$ should become $S_\mathit{next}$, we calculate its
selection probability, $P_1$, as
\begin{align*}
P_i & =
\begin{cases}
  1 & \mathit{cost}(S_{i}) < \mathit{cost}(S_{i - 1}) \\
  e^{-\frac{\mathit{cost}(S_{i}) - \mathit{cost}(S_{i - 1})}{T_i}} & \text{otherwise}
\end{cases} \\
P_1 & = 0.6777
\end{align*}

$S_1$ becomes $S_\mathit{next}$ if and only if a randomly selected number,
$r \in [0, 1]$, makes the inequality $r < P_1$ true.

Suppose we choose $r = 0.3597$. Because $0.3597 < 0.6777$
$$S_\mathit{next} = S_1 = [ 1, 2, 3, 0 ], \; \mathit{cost}(S_\mathit{next}) = 4.3288$$

\subsubsubsection{Iteration 2}

We begin by swapping two randomly selected elements (1 and 3) in $S_\mathit{next}$
$$S_2 = [ 3, 2, 1, 0 ], \; \mathit{cost}(S_2) = 4.6092$$

We calculate this solution's selection probability to be $P_2 = 0.8897$

Suppose we choose $r = 0.6329$. Because $0.6329 < 0.8897$ is true
$$S_\mathit{next} = S_2 = [ 3, 2, 1, 0 ], \; \mathit{cost}(S_\mathit{next}) = 4.6092$$

The best solution found so far is
$$S_\mathit{best} = [ 1, 2, 0, 3 ], \; \mathit{cost}(S_\mathit{best}) = 3.1617$$

\subsection{Genetic Algorithm} % Austin

\subsubsection{Description}

Genetic algorithms cover a large group of similar algorithms, so for our comparitive study we needed to specify an instance of Genetic Algorithm that solves our problem appropriately. Because this is a permutation problem we cannot encode our solution as a binary string, so we have to use a version of Genetic Algorithm that can handle permutations. Our solution representation is the same as described in the Problem Formulation section with each individual in a generation representing a particular solution.

To initialize our solver we will choose a random starting solution for each individual and then start the iterations. Each iteration will consist of crossover, mutation and then survivor selection. Each of these steps must be customized for the problem set, and there are multiple methods between which we had to choose.

For crossover we chose to use the Order 1 permutation as described in \cite{Eiben} which is a crossover algorithm that attempts to preserve the relative order of elements in a solution. It chooses a random subsection from one parent, copies those values into the first child and then fills the rest of the values in the same order that they appear in the second parent. This process is then mirrored for the second child so two children are produced from this crossover.

The mutation function is much easier to specify in a permutation problem, because there are fewer issues relating to creating invalid solutions which is a large issue when attempting to do a crossover. Mutation in our algorithm swaps the position of two or more elements in a solution and then creates a new child. The number of elements swapped can be configured depending on the size of the solution.

The last component that needs to be specified is the survivor selection algorithm. We chose to use a steady state Genetic Algorithm, so the entire generation and the children are considered when chosing the new generation. We use an elitism based selection method which causes our new generations to only contain the best members from the previous generation \cite{Talk}. This method was chosen because it caused the algorithm to converge faster to optimal values.

With our algorithm specified fully we can now do iterations by hand to see the results of our decisions.

\subsubsection{Hand Iterations}

The genetic algorithm metaheuristic has many different parameters that can be tuned and changed, but for the hand iteration we will choose values that show the different operations of the algorithm. We will use a generation size of 4 and choose $p_\mathit{crossover}=0.75$, and $p_\mathit{mutation}=0.25$ because $p_\mathit{mutation}$ must be between $$\frac{1}{\text{Population Size}} <= p_\mathit{mutation} < \frac{1}{\text{Chromosome Length}}$$ For every child, a random number, $r \in (0,1)$, will be generated. If $0<r\leq0.25$ then mutation will be applied, else if $0.25<r<1$ then crossover will be applied.

This is a permutation problem, so we will use the Order 1 crossover algorithm. We also choose the mutation operator to be a swap operation that swaps two elements in a solution.

\subsubsubsection{Iteration 1}

We generate 4 random solutions to be members of the first generation.

\begin{align*}
S_{0,1} = [1, 2, 0, 3], & \qquad cost(S_{0,1}) = 3.1617 \\
S_{0,2} = [3, 2, 0, 1], & \qquad cost(S_{0,2}) = 3.6619 \\
S_{0,3} = [2, 0, 1, 3], & \qquad cost(S_{0,3}) = 2.9759 \\
S_{0,4} = [3, 2, 1, 0], & \qquad cost(S_{0,4}) = 4.6092
\end{align*}

We now generate a random number to see if crossover or mutation will produce the first child(ren). $r=0.37$ so we will use crossover.

We will perform the crossover by choosing two random parents, $S_{0,1}$ and $S_{0,3}$. We apply Order 1 crossover, with the two crossover points as 1 and 2. The two children will be:

\begin{align*}
S_{1,1} = [1, 2, 3, 0], & \qquad cost(S_{1,1}) = 4.3288 \\
S_{1,2} = [2, 0, 3, 1], & \qquad cost(S_{1,2}) = 3.0201
\end{align*}


Another random number is genereated: $r=0.65$, another crossover. This crossover will be between $S_{0,2}$ and $S_{0,4}$, with crossover points as 2 and 4. This yields two more children:

\begin{align*}
S_{1,3} = [3, 2, 0, 1], & \qquad cost(S_{1,3}) = 3.6619 \\
S_{1,4} = [3, 2, 1, 0], & \qquad cost(S_{1,4}) = 4.6092
\end{align*}


The next generation is selected using the cost based elitism survivor selection; we will pick the best 4 solutions from the 8 candidates. The result of this selection is:

\begin{align*}
S_{1,1} = [1, 2, 0, 3], & \qquad cost(S_{1,1}) = 3.1617 \\
S_{1,2} = [2, 0, 3, 1], & \qquad cost(S_{1,2}) = 3.0201 \\
S_{1,3} = [2, 0, 1, 3], & \qquad cost(S_{1,3}) = 2.9759 \\
S_{1,4} = [3, 2, 0, 1], & \qquad cost(S_{1,4}) = 3.6619
\end{align*}

\subsubsubsection{Iteration 2}
A random number is generated: $r=0.89$, a crossover. This crossover will be between parents $S_{1,1}$ and $S_{1,2}$ and use crossover points 3 and 4.

\begin{align*}
S_{2,1} = [2, 1, 0, 3], & \qquad cost(S_{2,1}) = 3.8583 \\
S_{2,2} = [2, 0, 3, 1], & \qquad cost(S_{2,2}) = 3.0201
\end{align*}

The next random number is: $r=0.18$, a mutation. We will mutate one randomly chosen parent, $S_{1,2}$, by swapping the randomly chosen indicies 3 and 4.

\begin{align*}
S_{2,3} = [2, 1, 3, 0], & \qquad cost(S_{2,3}) = 4.6371
\end{align*}

The next random number is: $r=0.05$, a mutation. We will mutate one randomly chosen parent, $S_{1,4}$ by swapping the randomly chosen indicies 1 and 2.

\begin{align*}
S_{2,4} = [2, 3, 0, 1], & \qquad cost(S_{2,4}) = 4.0781
\end{align*}

Again, cost-based elitism survivor selection is used to pick the best 4 solutions from both generations. We are left with the same generation as the last iteration because none of the children had a higher fitness score than any of the parents.

\begin{align*}
S_{2,1} = [1, 2, 0, 3], & \qquad cost(S_{2,1}) = 3.1617 \\
S_{2,2} = [2, 0, 3, 1], & \qquad cost(S_{2,2}) = 3.0201 \\
S_{2,3} = [2, 0, 1, 3], & \qquad cost(S_{2,3}) = 2.9759 \\
S_{2,4} = [3, 2, 0, 1], & \qquad cost(S_{2,4}) = 3.6619
\end{align*}

\subsection{Particle Swarm Optimization Algorithm} % Ariel
The particle Swarm Optimization (PSO) metaheuristic is based on the behavior of swarm animals such as fish and birds.
Each particle represents a candidate solution and ``flies'' towards the optimal solution using information from its
past experience and the swarm's experience. Gradually, the particles will converge on the ideal solution.
The algorithm begins by generating an initial population of particles each of whom have a velocity of 0.
In each iteration, the local (per particle) and global (across the swarm) best values are recorded and used to calculate each particle's velocity. \cite{ClassicalPSO}
Velocity is calculated by:
$$
v_\mathit{next} = wv_\mathit{current} + c_1r_1(l_\mathit{best} - x) + c_2r_2(g_\mathit{best}-x)
$$

Where $w$ is a constant representing a particle's inertia, $c_1$ \& $c_2$ are two pre-selected parameters to adjust the relative importance of a particle's individual memory versus the swarm's collective memory. The random numbers $r_1$ \& $r_2$ are random numbers $\in (0,1)$ that are generated per iteration. $l_\mathit{best}$ is the best position a particle has been in and $g_\mathit{best}$ is the best position that any particle in the swarm has
been in. The overall algorithm can be visualized as follows \cite{PSOFigure}:

\includegraphics[width=1\textwidth]{images/PSO.png}

Where satisfy criteria is defined in this report as performing a specified number of iterations.\\

Now, mTSP is a permutation problem and therefore this report is making modification to the classical PSO algorithm.
The difficulty arises from the fact that position and velocity do not have a natural meaning when working
with permutations rather than continuous values.
M. Clerc proposed a modification of PSO that could be applied to the Travelling Salesman problem.
Every particle's position is a candidate solution which is a permutation of tasks and homes and
a particle's velocity consists of a set of swaps that should be performed on its position.
Clerc re-definitions of the operators for adding a velocity to a position, multiplying a velocity by a scalar, and subtracting two positions
are used. Adding a velocity to a position is defined as performing all of the swaps on the position.
Multiplying a velocity by a scalar results in a new velocity that consists of $scalar\cdot |velocity|$ swaps; which is achieved
through truncation or augmentation with swaps repeated from the existing velocity.
Subtracting two positions results in a velocity that consists of the swaps needed to turn the first position into the second position.
With these new operations, the classical PSO algorithm can be used. \cite{PermutationPSO}

\subsubsection{Hand Iterations}

% TODO don't say "in this course", find the actual citation.
As per the recommendations in this course, we set the following constants
\begin{align*}
c_1 = c_2 & = 1.4944 \\
w & = 0.792
\end{align*}

\subsubsubsection{Iteration 1}

Let $r_1 = 0.7426$ and $r_2 = 0.4276$ as random constants for this iteration.

We start with three randomly selected initial positions (solutions)
\begin{align*}
S_{1,1} = [1, 2, 0, 3], & \; cost(S_{1,1}) = 3.1617 \\
S_{1,2} = [3, 2, 0, 1], & \; cost(S_{1,2}) = 3.6619 \\
S_{1,3} = [1, 0, 3, 2], & \; cost(S_{1,3}) = 3.6494
\end{align*}

Observe that $S_{1,1}$ has the lowest initial score. This becomes our initial $S_\mathit{gbest}$.
$$S_\mathit{gbest} = [1, 2, 0, 3], \; cost(S_\mathit{gbest}) = 3.1617$$

For this algorithm, we track not only the best solution seen globally,
$S_\mathit{gbest}$, but the best solution seen by each particle, $i$, as
$S_{\mathit{lbest}, i}$.

% TODO create a proper citation to paper
For each position, $i$, we calculate
$v_{1,i}$ using the following equation. Note that we redefine the subtraction of
two positions, the addition of a velocity and a position, and the multiplication
of a velocity by a scalar as defined in M. Clerc's paper, ``Discrete Particle
Swarm Optimization."
$$
v_{j,i} =
  w v_{j-1, i} +
  c_1 r_1 (S_{\mathit{lbest}, i} - S_{j-1, i}) +
  c_2 r_2 (S_\mathit{gbest} - S_{j-1, i})
$$

\begin{center}
\begin{tabular}{lllllll}
          & \textbf{position} & \textbf{cost} & \textbf{lbest position} & \textbf{lbest cost} & $v_1$ & $v_2$            \\
$S_{1,1}$ & $[1, 2, 0, 3]$    & $3.1617$      & $[1, 2, 0, 3]$          & $3.1617$            & $[]$  & $[]      $ \\
$S_{1,2}$ & $[3, 2, 0, 1]$    & $3.6619$      & $[3, 2, 0, 1]$          & $3.6619$            & $[]$  & $[(1, 4)]$ \\
$S_{1,3}$ & $[1, 0, 3, 2]$    & $3.6494$      & $[1, 0, 3, 2]$          & $3.6494$            & $[]$  & $[(2, 4)]$ \\
\end{tabular}
\end{center}
\vspace{1.5em}

\subsection{Iteration 2}

We choose $r_1 = 0.2351$ and $r_2 = 0.8262$ as random constants for this
iteration.

Applying the $v_2$ velocities calculated in iteration 1 to the positions in
iteration 1, we obtain the positions for iteration 2 and calculate new
velocities accordingly
\begin{center}
\begin{tabular}{lllllll}
          & \textbf{position} & \textbf{cost} & \textbf{lbest position} & \textbf{lbest cost} & $v_1$      & $v_2$            \\
$S_{2,1}$ & $[1, 2, 0, 3]$    & $3.1617$      & $[1, 2, 0, 3]$          & $3.1617$            & $[]      $ & $[]$             \\
$S_{2,2}$ & $[1, 2, 0, 3]$    & $3.1617$      & $[1, 2, 0, 3]$          & $3.1617$            & $[(1, 4)]$ & $[]$             \\
$S_{2,3}$ & $[1, 2, 3, 0]$    & $4.3288$      & $[1, 0, 3, 2]$          & $3.6494$            & $[(2, 4)]$ & $[(3,4), (3,4)]$ \\
\end{tabular}
\end{center}
\vspace{1.5em}

After two iterations, we have
$$S_\mathit{gbest} = [1, 2, 0, 3], \; cost(S_\mathit{gbest}) = 3.1617$$

\subsection{Ant Colony Optimization Algorithm} % Sandy

We are using a variation of ACS to solve this instance of complex task allocation.

Let us define the pheromone evaporation constant $\rho=0.7$.\\
The desirability function is defined as:


\begin{equation*}
\resizebox{0.9\textwidth}{!}{$
\mathit{d}(r, t_\mathit{from}, t_\mathit{to}) = \begin{cases}
  0 & \text{if } t_\mathit{to} = \mathit{home}(robot) \\
  \left(
  (1 - \alpha)
    (\mathit{priority}(t_\mathit{to}) \mathit{skill}(r, t_\mathit{to})) +
    \alpha \beta
    \mathit{e}_{cost}(t_\mathit{from}, t_\mathit{to})
  \right)^{-1}
  & \text{if }\mathit{accomplishable}(r, t_\mathit{from}, t_\mathit{to}) \\
  - \infty
  & \text{otherwise} \\
\end{cases}
$}
\end{equation*}
Where $\mathit{accomplishable}$ is defined as:
$$
\mathit{accomplishable}(r, t_\mathit{from}, t_\mathit{to}) =
\frac{\mathit{round\,trip}(r, t_\mathit{from}, t_\mathit{to})}{velocity(r)} + \mathit{task \, time}(r, t_\mathit{to}) \leq \mathit{energy}_r
$$
for 
$$
\mathit{round\,trip}(r, t_\mathit{from}, t_\mathit{to}) = \mathit{distance}(t_\mathit{from}, t_\mathit{to}) + \begin{cases}
\mathit{distance}(t_\mathit{to}, \mathit{home}(r)) & \text{if } t_\mathit{to} \ne \mathit{home}(r) \\
0 & \text{otherwise} 
\end{cases}
$$

We define an $r_o$ value that will be used to control the level of exploitation versus the level of exploration by the ants.
For each state transition the ant makes, a random number, $r$, is generated.
If $r<=r_o$ then the most desirable path (weighted by pheromones) is exploited, else if $r>r_0$
a randomly selected path is explored. We will use a value of $r_0=0.43$.

The most desirable path is defined as the neighboring node that maximizes:
$$
\tau_{iu}\eta_{iu}^\beta
$$
Where $i$ represents the current node of the ant and $u$ is a neighboring node.

For exploration, random path selection is done via the Roulette Wheel Method.
Probabilities are generated by:
$$
p_{ij}=
\begin{cases}
\frac{\tau_{ij}\eta_{ij}^\beta}{\sum\limits_{u\in N_i} \tau_{iu}\eta_{iu}^\beta} & \text{if } j \in N_i\\
0 & \text{if } j \not\in N_i
\end{cases}
$$
Where $N_i$ represents the neighbors of node $i$.

The most important modification to ACS is how the sentinel values in a given solution $S$ are handled.
The key insight for this change is a subtle modification of the graph during search-time. Define the distance between any
two $home$s to be 0, and, at first, connect each task node only to $home(1)$.

Upon returning to $\mathit{home}(1)$, ``teleport'' the ant to $\mathit{home}(2)$, connecting it to all
of the task nodes, and disconnecting the tasks from $\mathit{home}(1)$. In effect, we are swapping the node associated with $\mathit{home}(1)$ out with the node $\mathit{home}(2)$. Upon doing this, update an
internal state variable $robot_{current}$, whose purpose it is to correctly
evaluate the $d()$ function.

The first two iterations of performing ACS on the reduced problem are shown below:

\subsubsection{Iteration 1}

The starting node is $\mathit{home}(1) = 4$.

using params:
homeConst =  0.50000
exploitConst =  1
exploreConst =  1
rho =  0.70000
rnaught =  0.50000


\subsubsubsection{Ant Travel}
$$
\eta = \sum_{n \in N_4} \uptau_{4n}^\alpha d_{4n}^\beta = 6.2913
$$

\begin{align*}
p_{4i} &= \frac{\uptau_{4n}^\alpha d_{4i}^{-\beta}}{\eta} \\
\\
p_{41} &= 0.26070 \\
\mathbf{p_{42}} &= \mathbf{0.25154} \\
p_{43} &= 0.24933 \\
p_{44} &= 0.23842
\end{align*}

$$
\text{Tour} = \{4, 2\} \qquad \mathit{energy}(1) = 40.096
$$

% % %

$$
\eta = \sum_{n \in N_2} \uptau_{2n}^\alpha d_{2n}^\beta = 4.5890
$$

\begin{align*}
p_{2i} &= \frac{\uptau_{2n}^\alpha d_{2i}^{-\beta}}{\eta} \\
\\
\mathbf{p_{21}} &= \mathbf{0.34080} \\
p_{23} &= 0.33233 \\
p_{24} &= 0.32687
\end{align*}

$$
\text{Tour} = \{2, 1\} \qquad \mathit{energy}(1) = 28.742
$$

% % %

$$
\eta = \sum_{n \in N_1\setminus\{2\}} \uptau_{1n}^\alpha d_{1n}^\beta = 3.0489
$$

\begin{align*}
p_{1i} &= \frac{\uptau_{1n}^\alpha d_{1i}^{-\beta}}{\eta} \\
\\
\mathbf{p_{13}} &= \mathbf{0.50802}
p_{14} &= 0.49198 \\
\end{align*}

$$
\text{Tour} = \{4, 2, 1, 3, 4, 5\} \qquad \mathit{energy}(1) = 6.4352 \qquad d_{tour} = 6.1953
$$

Note that traveling to $\textit{home}(1) = 4$ has triggered the ant to automatically move to $\textit{home}(2) = 5$, and thus the ant now uses $robot_2$'s cost function.

\subsubsubsection{Update Pheromone Trail}
$$
\uptau = (1 - \rho)\uptau =
\begin{tabular}{r | c c c c c}
$i \setminus j$ & 1 & 2 & 3 & 4 & 5 \\
\hline
1 & 0.30000 & 0.30000 & 0.30000 & 0.30000 & 0.30000 \\
2 & 0.30000 & 0.30000 & 0.30000 & 0.30000 & 0.30000 \\
3 & 0.30000 & 0.30000 & 0.30000 & 0.30000 & 0.30000 \\
4 & 0.30000 & 0.30000 & 0.30000 & 0.30000 & 0.30000 \\
5 & 0.30000 & 0.30000 & 0.30000 & 0.30000 & 0.30000
\end{tabular}
$$

$$
\uptau_{ij} = \uptau_{ij} + Q/\mathit{cost}(\text{Tour}) =
\begin{tabular}{r | c c c c c}
$i \setminus j$ & 1 & 2 & 3 & 4 & 5 \\
\hline
1 & 0.30000 & 0.30000 & 0.51565 & 0.30000 & 0.30000 \\
2 & 0.51565 & 0.30000 & 0.30000 & 0.30000 & 0.30000 \\
3 & 0.30000 & 0.30000 & 0.30000 & 0.51565 & 0.30000 \\
4 & 0.30000 & 0.51565 & 0.30000 & 0.30000 & 0.51565 \\
5 & 0.30000 & 0.30000 & 0.30000 & 0.30000 & 0.51565
\end{tabular}
$$



\subsubsection{Iteration 2}

\subsubsubsection{Ant Travel}
$$
\eta = \sum_{n \in N_4} \uptau_{4n}^\alpha d_{4n}^\beta = 2.2287
$$

\begin{align*}
p_{4i} &= \frac{\uptau_{4n}^\alpha d_{4i}^{-\beta}}{\eta} \\
\\
p_{41} &= 0.22078 \\
p_{42} &= 0.36615 \\
\mathbf{p_{43}} &= \mathbf{0.21115} \\
p_{44} &= 0.20192
\end{align*}

$$
\text{Tour} = \{4, 3\} \qquad \mathit{energy}(1) = 47.028
$$

% % %

$$
r < r_0 \to \text{automatically choose most desirable path, 4}
$$

$$
\text{Tour} = \{4, 3, 4, 5\} \qquad \mathit{energy}(1) = 37.704
$$

Note that because node 4 was visited, 5 was also visited and now $robot_{current} = 2$.

% % %

$$
\eta = \sum_{n \in N_5\setminus\{3\}} \uptau_{2n}^\alpha d_{5n}^\beta = 1.0070
$$

\begin{align*}
p_{3i} &= \frac{\uptau_{2n}^\alpha d_{1i}^{-\beta}}{\eta} \\
\\
p_{31} &= 0.50890 \\
\mathbf{p_{32}} &= \mathbf{0.49110}
\end{align*}

$$
\text{Tour} = \{4, 3, 4, 5, 2, 1\} \qquad \mathit{energy}(2) = 13.132 \qquad d_{tour} = 3.2795
$$

Node 1 was automatically selected since after choosing 2, it was all that remained.

\subsubsubsection{Update Pheromone}

$$
\uptau = (1 - \rho)\uptau =
\begin{tabular}{r | c c c c c}
$i \setminus j$ & 1 & 2 & 3 & 4 & 5 \\
\hline
1 & 0.090000 & 0.090000 & 0.154696 & 0.090000 & 0.090000 \\
2 & 0.154696 & 0.090000 & 0.090000 & 0.090000 & 0.090000 \\
3 & 0.090000 & 0.090000 & 0.090000 & 0.154696 & 0.090000 \\
4 & 0.090000 & 0.154696 & 0.090000 & 0.090000 & 0.154696 \\
5 & 0.090000 & 0.090000 & 0.090000 & 0.090000 & 0.154696
\end{tabular}
$$

$$
\uptau_{ij} = \uptau_{ij} + Q/\mathit{cost}(\text{Tour}) =
\begin{tabular}{r | c c c c c}
$i \setminus j$ & 1 & 2 & 3 & 4 & 5 \\
\hline
1 & 0.090000 & 0.090000 & 0.154696 & 0.090000 & 0.355319 \\
2 & 0.420015 & 0.090000 & 0.090000 & 0.090000 & 0.090000 \\
3 & 0.090000 & 0.090000 & 0.090000 & 0.420015 & 0.090000 \\
4 & 0.090000 & 0.154696 & 0.355319 & 0.090000 & 0.420015 \\
5 & 0.090000 & 0.355319 & 0.090000 & 0.090000 & 0.154696
\end{tabular}
$$

\subsubsection{Result}

$$
\text{Tour}_{best} = \{4, 1, 2, 4, 5, 3, 5\} \qquad d_{best} = 0.8900
$$

\section{Performance Evaluation}

% Define some experiments (scenarios) to quantitatively evaluate the performance
% of your algorithm. Experiments must be run several cdot and average results
% should be reported

% Establish a set of evaluation metrics and run some experiments with different
% values of algorithm parameters to quantitatively and qualitatively assess the
% performance of the developed solution using different metaheuristic
% optimization techniques. Students must identify the pros and cons of each
% technique and assess the quality of work as well as its fit with project
% objectives.

% Report your observation and interpret the obtained results. Suggest how to
% refine the implemented solutions to improve their performance.

% The implemented solutions should be tested against a set of well-defined
% evaluation metrics. These metrics may include, but are not limited to, the CPU
% time of the algorithm, number of iterations to converge, time per iteration,
% optimality (if the ground truth is known), etc.

% A number of experiments/scenarios should be conducted to quantitatively
% evaluate the performance of the proposed solutions. You should run each
% experiment several cdot and report the average results.

% Determine some evaluation metrics (time is a potentially useful candidate) Run
% some experiments with different values of algorithms parameters to
% quantitatively and qualitatively assess the performance of the developed
% solution Identify the pros and cons of each method

Each metaheuristic will be evaluated quantitatively and qualitatively.

The following instances of MRTA will be studied:
\begin{enumerate}
\item \textbf{Small scale}: Five tasks and three robots
\item \textbf{Medium scale}: Fifteen tasks and five robots
\item \textbf{Large scale}: Fifty tasks and fifteen robots
\end{enumerate}

The different scenarios will allow for qualitative analysis on the scalability of metaheuristic techniques and where they are best applied. Within each scenario, each technique can be compared using some quantitative metrics. Badreldin et al. \cite{Badreldin} identify two suitable measures: the computational time taken to find the best solution and the optimality of the best solution obtained by a metaheuristic technique.

\subsection{Small Scale}

\subsection{Medium Scale}

\subsection{Large Scale}

\section{Conclusions \& Recommendations}
% Report your observation and interpret obtained results. Briefly explain your
% research work, and suggest how to improve the implemented solutions

% Summarize the conclusion and future improvement. Explain how did you solve the
% problem, what problems were met? What did the results show? and how to refine
% the proposed solution? You may organize ideas using lists or numbered points,
% if appropriate, but avoid making your report into a check-list or a series of
% encrypted notes.

This paper has presented a comparative study of metaheuristic algorithms used within an optimization based approach to solving the MRTA problem. Five metaheuristics were considered: Tabu Search, Simulated Annealing, Genetic Algorithms, Particle Swarm optimization, and Ant Colony Optimization. RECAP RESULTS OF EXPERIMENTS.

\printbibliography

% Every report needs references; in fact, your failure to consult references for
% guidance may be considered negligence. On the other hand, when you include
% sentences, photos, drawings or figures from other sources in your report, the
% complete reference must be cited. Failure to do so is plagiarism, an academic
% infraction with serious consequences.

% Remember to cite anything you get from other sources
%  - Other research papers
%  - Drawings, charts, figures, etc.

% Failure to do so is plagiarism, an academic infraction with serious
% consequences. The complete references should be shown at the end of your
% report



% M. Clerc, “Discrete Particle Swarm Optimization,” in New Optimization Techniques in Engineering. Springer-Verlag, 2004.

\end{document}
